[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Exchange Rate Forecasting Using Bayesian VARs Model",
    "section": "",
    "text": "Abstract. This research report explores how Bayesian VARs model predict AUD/USD exchange rate. Keywords. Bayesian Vars, Exchange rate, Forecasting, Minnesota Prior, Laplace distribution"
  },
  {
    "objectID": "index.html#the-basic-model",
    "href": "index.html#the-basic-model",
    "title": "Exchange Rate Forecasting Using Bayesian VARs Model",
    "section": "The basic model",
    "text": "The basic model\n\\[\\begin{align}\nY &=XA+E\\\\\nE|X&\\sim \\mathcal{MN}_{T\\times N}(0, \\Sigma, I_T)\\\\\nY|X,A,\\Sigma&\\sim \\mathcal{MN}_{T\\times N} (XA, \\Sigma, I_T)\n\\end{align}\\]\nWhere \\(Y\\) is a \\(T\\times 13\\) Matrix, \\(X\\) is a \\(T\\times(1+p\\times13)\\), \\(A\\) is a \\((1+p\\times13)\\times13\\) matrix that contains \\(\\mu_{0}\\) and vectors of the autoregressive slope parameters and \\(E\\) is a \\(T\\times13\\) matrix contains vetors of error terms.\nThe kernel of the likelihood function:\n\\[\\begin{align}\nL(A,\\Sigma|Y,X) \\propto det(\\Sigma)^{-\\frac{T}{2}}exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}(Y-XA)'(Y-XA)]\\}\n\\end{align}\\]\nThe basic model is based on Natural-conjugate prior distribution, where the \\(A\\) follows a Matrix-variate Normal distribution and \\(\\Sigma\\) follows an Inverse Wishart distribution.\n\\[\\begin{align}\np(A,\\Sigma) &= p(A|\\Sigma)p(\\Sigma) \\\\\nA|\\Sigma &\\sim \\mathcal{MN}_{K \\times N}(\\underline{A},\\Sigma,\\underline{V}) \\\\\n\\Sigma &\\sim \\mathcal{IW}_N(\\underline{S},\\underline{\\nu})\n\\end{align}\\]\nThe Minnesota prior is typically a good choice for specifying priors in BVAR model especially when the model involves many macroeconomic variables. It assumes the variables follow a random walk and it is suitable for unit root non-stationary variables such as in our case, most variables are integrated at 1 at the 5% significance level of the ADF test, where:\n\\[\\begin{align}\n\\underline{A} &= \\begin{bmatrix}0_{N \\times 1} & I_{N} & 0_{N \\times (p-1)N}\\end{bmatrix}'\\\\\n\n\\underline{V} &= diag( \\begin{bmatrix} \\kappa_2 & \\kappa_1(p^{-2}\\otimes I_N') \\end{bmatrix})\n\n\\end{align}\\]\nThe prior mean \\(\\underline{A}\\) for the first lag of each variable (the identity matrix portion) is one, while all other coefficients including intercepts, are zeroes. For the column-specific prior covariance \\(\\underline{V}\\), two shrinkage hyper-parameters \\(\\kappa_1\\) and \\(\\kappa_2\\) represent the overall shrinkage level for slopes and constant terms respectively.\nFor posterior distribution, the kernel of the posterior distribution takes the form of the product of the likelihood and the prior distributions.\n\\[\\begin{align*}\np(A,\\Sigma|Y,X) &\\propto L(A,\\Sigma|Y,X)p(A,\\Sigma) \\\\\n&= L(A,\\Sigma|Y,X)p(A|\\Sigma)p(\\Sigma)\n\\end{align*}\\]\n\\[\\begin{align}\np(A,\\Sigma|Y,X) &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\\\\n&\\times exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}(Y-XA)'(Y-XA)]\\} \\\\\n&\\times \\det(\\Sigma)^{-\\frac{N+K+\\underline{v}+1}{2}} \\\\\n&\\times exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}(A-\\underline{A}) \\underline{V}^{-1}(A-\\underline{A})]\\} \\\\\n&\\times exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}\\underline{S}]\\}\n\\end{align}\\]\nThe kernel can be represent as the normal-inverse Wishart distribution and we can get the following full conditional joint posterior distribution: \n\\[\\begin{align}\np(A|Y,X,\\Sigma) &= \\mathcal{MN}_{K \\times N}(\\bar{A}, \\Sigma, \\bar{V}) \\\\\np(\\Sigma|Y,X) &= \\mathcal{IW}_N(\\bar{S},\\bar{\\nu}) \\\\\n\\\\\n\\bar{V} &= (X'X + \\underline{V}^{-1})^{-1} \\\\\n\\bar{A} &= \\bar{V}(X'Y + \\underline{V}^{-1}\\underline{A}) \\\\\n\\bar{\\nu} &= T + \\underline{\\nu} \\\\\n\\bar{S} &= \\underline{S} + Y'Y + \\underline{A}'\\underline{V}^{-1}\\underline{A} - \\bar{A}'\\bar{V}^{-1}\\bar{A} \\\\\n\n\\end{align}\\]"
  },
  {
    "objectID": "index.html#the-extended-model",
    "href": "index.html#the-extended-model",
    "title": "Exchange Rate Forecasting Using Bayesian VARs Model",
    "section": "The extended model",
    "text": "The extended model\nThe extended model will be built based on the the change in distribution of the error to Laplace distribution instead of the normally distributed errors assumption. The Laplace distribution is suitable for describing financial anomalies due to its sharp peaks and thick tails and the use of this distribution improves the robustness of the model to anomalies and is particularly suitable for financial time series. As our variables are most financial time series data, a Laplace distribution is more suitable to apply to our error term.\nFollowing Eltoft,Kim, and Lee 2006b, for covariance with a general Kronecker structure, if each \\({\\lambda_t}\\) has an independent exponential distribution with mean \\({\\alpha}\\), then marginally \\({U_t}\\) has a multivariate Laplace distribution with mean vector 0 and covariance matrix \\({\\alpha\\Sigma}\\).\n\\[\\begin{align}\nU_t &\\sim \\text{Laplace}(0, \\alpha\\Sigma) \\\\\nU_t | \\lambda_t &\\sim \\mathcal{MN}(0, \\Sigma, \\lambda_t I_T) \\\\\n\\lambda_t &\\sim \\text{Exponential}(\\frac{1}{\\alpha})\n\\end{align}\\]\nThe kernel of the likelihood function:\n\\[\\begin{align}\nL(A,\\Sigma,\\lambda_t|Y,X) &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\det(\\lambda_t I_T)^{-\\frac{N}{2}} exp\\{-\\frac{1}{2} tr[\\Sigma^{-1} (Y-XA)' (\\lambda_t I_T)^{-1} (Y-XA) ]\\}\n\\end{align}\\]\nFor posteriors distribution, \\(A\\), \\(\\Sigma\\) and \\(\\lambda_t\\) can then be derived using the likelihood and the prior distributions as follows:\n\\[\\begin{align}\np(A,\\Sigma|Y,X) &\\propto L(A,\\Sigma,\\lambda_t|Y,X)p(A,\\Sigma) \\\\\n\\\\\n&= \\det(\\Sigma)^{-\\frac{T}{2}} \\det(\\lambda_t I_T)^{-\\frac{N}{2}} exp\\{-\\frac{1}{2} tr[\\Sigma^{-1} (Y-XA)' (\\lambda_t I_T)^{-1} (Y-XA) ]\\} \\\\\n&\\times \\det(\\Sigma)^{-\\frac{N+k+\\underline{\\nu}+1}{2}} exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}(A-\\underline{A})'(\\underline{V})^{-1}(A-\\underline{A})]\\} \\\\\n&\\times exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}\\underline{S}]\\} \\\\\n&= \\det(\\Sigma)^{-\\frac{T+N+K+\\underline{\\nu}+1}{2}} \\det(\\lambda_t I_T)^{-\\frac{N}{2}} \\\\\n&\\times exp\\{-\\frac{1}{2} tr[\\Sigma^{-1}(Y'(\\lambda_t I_T)^{-1}Y - 2A'X'(\\lambda_t I_T)^{-1}Y + A'X'(\\lambda_t I_T)^{-1}XA \\\\\n&+ A'\\underline{V}^{-1}A -2A'\\underline{V}^{-1}\\underline{A} + \\underline{A}'\\underline{V}^{-1}\\underline{A} + \\underline{S})]\\}\n\n\\end{align}\\]\nThe kernel can be rearranged in the form of the Matrix-variate normal-inverse Wishart distribution.\n\\[\\begin{align}\np(A,\\Sigma|Y,X) &\\sim MNIW(\\bar{A},\\bar{V},\\bar{S},\\bar{\\nu}) \\\\\n&\\\\\n\\bar{V} &= (X'(\\lambda_t I_T)^{-1}X + \\underline{V}^{-1})^{-1} \\\\\n\\bar{A} &= \\bar{V}(X'(\\lambda_t I_T)^{-1}Y + \\underline{V}^{-1}\\underline{A}) \\\\\n\\bar{\\nu} &= T + \\underline{\\nu}\\\\\n\\bar{S} &= Y'(\\lambda_t I_T)^{-1}Y + \\underline{A}'\\underline{V}^{-1}\\underline{A} + \\underline{S} - \\bar{A}'\\bar{V}^{-1}\\bar{A}\n\\end{align}\\]\nThe kernel of the fully conditional posterior distribution of \\(\\lambda_t\\) is then derived as follows:\n\\[\\begin{align}\np(\\lambda_t|Y,X,A,\\Sigma) &\\propto L(A,\\Sigma,\\lambda_t|Y,X)p(\\lambda_t) \\\\\n\\\\\n&\\propto \\det(\\lambda_t I_T)^{-\\frac{N}{2}} exp\\{-\\frac{1}{2} tr[\\Sigma^{-1} (Y-XA)' (\\lambda_t I_T)^{-1} (Y-XA) ]\\} \\\\\n&\\times \\frac{1}{\\alpha}exp\\{ -\\frac{1}{\\alpha}\\lambda_t \\}\\\\\n\n&= \\lambda_t^{-\\frac{TN}{2}} exp\\{-\\frac{1}{2}\\frac{1}{\\lambda_t} tr[\\Sigma^{-1}(Y-XA)'(Y-XA)]\\}\\\\\n&\\times exp\\{-\\frac{1}{\\alpha}\\lambda_t \\}\\\\\n\n&= \\lambda_t^{-\\frac{TN}{2}+1-1} exp\\{-\\frac{1}{2}[\\frac{[tr[\\Sigma^{-1}(Y-XA)'(Y-XA)]}{\\lambda_t} +\\frac{2}{\\alpha}\\lambda_t]\\}\n\\end{align}\\]\nThe above expression can be rearranged in the form of a Generalized inverse Gaussian distribution kernel as follows:\n\\[\\begin{align}\n\\lambda_t|Y,A,\\Sigma &\\sim GIG(a,b,p) \\\\\n\\\\\na &=\\frac{2}{\\alpha} \\\\\nb &= tr[\\Sigma^{-1}(Y-XA)'(Y-XA)] \\\\\np &= -\\frac{TN}{2}+1\n\\end{align}\\]"
  },
  {
    "objectID": "index.html#proof-of-model-validity",
    "href": "index.html#proof-of-model-validity",
    "title": "Exchange Rate Forecasting Using Bayesian VARs Model",
    "section": "Proof of model validity",
    "text": "Proof of model validity\n\nProof of basic model validity\nTo test the model validity, we simulated 1000 observations from a bi-variate Gaussian random walk process with the covariance matrix equal to the identity matrix of order 2 to see how the autoregressive and the covariance matrices and the posterior mean of the constant term behave.\n\n\n\n\n\n\n\n\nPosterior mean of the covariance matrix Sigma\n\n\n\nSimulation_Y1\nSimulation_Y2\n\n\n\n\nY1-Lag\n0.9804481\n0.0891369\n\n\nY2-Lag\n0.0891369\n1.0182041\n\n\n\n\n\n\n\n\nPosterior mean of the autoregressive coefficient matrix A\n\n\n\nSimulation_Y1\nSimulation_Y2\n\n\n\n\nConstant\n0.0609321\n0.0765025\n\n\nY1-Lag\n0.9894527\n0.0048336\n\n\nY2-Lag\n0.0023207\n0.9959293\n\n\n\n\n\nThe diagonal entries of the covariance matrix are close to 1, which indicates that each variable has a strong autoregressive relationship with itself and similarly, the diagonal elements of the autoregressive coefficient matrix are close to one, suggesting that each variable is heavily influenced by its past value. Besides, the posterior means for the constant terms is close to 0, the above can indicate that the estimated parameter constant term and means are consistent with what we expect given a Minnesota prior.\n\n\nProof of extended model\nThe Gibbs sampler method will be applied to generate random draws from the full conditional posterior distribution:\n\nDraw \\(\\Sigma^{(s)}\\) from the \\(IW(\\bar{S},\\bar{\\nu})\\) distribution.\nDraw \\(A^{(s)}\\) from the \\(MN(\\bar{A},\\Sigma^{(s)}, \\bar{V})\\) distribution.\nDraw \\(\\lambda_t^{(s)}\\) from \\(GIG(a,b,p)\\).\n\nRepeat steps 1, step 2 and 3 for \\(S_1\\)+\\(S_2\\)times.\nDiscard the first draws that allowed the algorithm to converge to the stationary posterior distribution.\nOutput is \\(\\left\\{ {A^{(s)}, \\Sigma^{(s)}}, \\lambda_t^{(s)}\\right\\}^{S_1+S_2}_{s=S_1+1}\\).\n\n\n\nPosterior mean of the covariance matrix Sigma\n\n\n\nSimulation_Y1\nSimulation_Y2\n\n\n\n\nY1-Lag\n0.9788129\n0.0878723\n\n\nY2-Lag\n0.0878723\n1.0174290\n\n\n\n\n\n\n\n\nPosterior mean of the autoregressive coefficient matrix A\n\n\n\nSimulation_Y1\nSimulation_Y2\n\n\n\n\nConstant\n0.0609175\n0.0811382\n\n\nY1-Lag\n0.9887131\n0.0050850\n\n\nY2-Lag\n0.0025897\n0.9955687\n\n\n\n\n\nSimilarly, the posterior mean of the autoregressive and the covariance matrices are close to an identity matrix and the posterior mean of the constant term is close to zero, so we can conclude that the extended model is also valid."
  },
  {
    "objectID": "index.html#forecasting-with-basic-model",
    "href": "index.html#forecasting-with-basic-model",
    "title": "Exchange Rate Forecasting Using Bayesian VARs Model",
    "section": "Forecasting with basic model",
    "text": "Forecasting with basic model\n\n\n\n\n\nThe above presents the historical and forecasting data the AUD/USD exchange rate. The exchange rate shows several peaks and troughs, indicating the volatility in the exchange rate over the years. For the three years forecasting, it shows a clear downward trend and reaching the lowest above 0.6 in 2026.\nRegard to the 3D with density intervals below, we could notice that the for each different predictive density at specific horizons, with the back wall we have the one period ahead predictive density and with the front we have the 12 period ahead density which is 3 years. We could see the distribution becomes lower and more dispersed with the increases of the horizon, as the data is more informative about the nearest developments in the future. Hence, one period predictive density is highly concentrated relative to others with smaller variance and taller peak. Similarly, the interval become more wider and dispersed resulting a more uncertainty for the future period forecasting.\n\n\n\n\n\n\nForecasting on extended model\n\n\n\n\n\nThe above presents the historical and forecasting data the AUD/USD exchange rate for the extended model. For the three years forecasting, it also shows a clear downward trend for the first half forecasting period and reaching below 0.06 in around 2025 and slightly increase back to 0.61 fo the following period.\nWith regard to the 3D with density intervals below, we could notice that the confidence interval widened a little.\n\n\n\n\n\nInteractive versions of the above 3D plots are provided below.\n\n\n\n\n\n\n\n\n\n\nThe 3D plots above allow us to access to alternative vantage points. We could notice that for the first few forecasting periods, the extended model has very sharp and concentrated densities around the point estimated, and it shows clearly heavy tails, which may increase the possibility of capturing extreme values that deviate significantly from the central forecast."
  },
  {
    "objectID": "Test.html",
    "href": "Test.html",
    "title": "test",
    "section": "",
    "text": "# log transformation of data\ncpi_au &lt;- log(cpi_au)\ncpi_us &lt;- log(cpi_us)\nrgdp_au &lt;- log(rgdp_au)\nrgdp_us &lt;- log(rgdp_us)\nimpor_au &lt;- log(impor_au)\nimpor_us&lt;- log(impor_us)\nexpor_au &lt;- log(expor_au)\nexpor_us&lt;- log(expor_us)\ngprice &lt;- log(gprice)\n\n\n\n\n\n\n\n\n\n\nx_varibales &lt;-  na.omit(merge(gprice,\n                            cpi_au, cpi_us, \n                            crate_au, crate_us, \n                            expor_au, expor_us,  \n                            impor_au, impor_us, \n                            rgdp_au, rgdp_us,\n                            unemr_au, unemr_us))\ncolnames(x_varibales)   = c(\"gold price\", \n                         \"cpi_au\",    \"cpi_us\", \n                         \"cashrate_au\",  \"cashrate_us\", \n                         \"export_au\", \"export_us\",\n                         \"import_au\",   \"import_us\",\n                         \"realgdp_au\", \"realgdp_us\",\n                         \"unemployemtrate_au\", \"unemployemtrate_us\")\n\n\n# Compute correlation matrix\ncorrelation_matrix &lt;- cor(merged_data)\n\n# Find the row number corresponding to \"erate\"\nerate_row &lt;- which(rownames(correlation_matrix) == \"erate\")\n\n# Extract correlations between erate and other variables\ncorrelations_erate &lt;- correlation_matrix[erate_row, names(merged_data) != \"erate\"]\n\n# Print correlation values\nprint(correlations_erate)\n\n     exchange rate cpi_au cpi_us cashrate_au cashrate_us export_au export_us\n     import_au import_us realgdp_au realgdp_us unemployemtrate_au\n     unemployemtrate_us\n\n\n\nAugmented Dickey-Fuller test for log transformed variables except exchange rate and cash rate.\n\npar(mfcol = c(3, 2), mar=c(2,2,2,2))\nfor (i in 1:6){\nacf = acf(merged_data[,i], plot = FALSE)[1:20]\nplot(acf, main = \"\")\ntitle(main = paste(colnames(merged_data)[i]), line = 0.5)\n}\n\n\n\npar(mfrow = c(3, 2), mar=c(2,2,2,2))\nfor (i in 7:13){\nacf = acf(merged_data[,i], plot = FALSE)[1:20]\nplot(acf, main = \"\")\ntitle(main = paste(colnames(merged_data)[i]), line = 0.5)\n}\n\n\n\n\n\n\n\n\nadf_test &lt;- list()\nfor (i in 1:13) {\n  adf_result = adf.test(merged_data[,i], k = 4)\n  adf_test[[i]] &lt;- adf_result\n}\n\nprint(adf_test)\n\n[[1]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -2.0604, Lag order = 4, p-value = 0.5507\nalternative hypothesis: stationary\n\n\n[[2]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -1.9709, Lag order = 4, p-value = 0.5871\nalternative hypothesis: stationary\n\n\n[[3]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -1.355, Lag order = 4, p-value = 0.8378\nalternative hypothesis: stationary\n\n\n[[4]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -0.84089, Lag order = 4, p-value = 0.9536\nalternative hypothesis: stationary\n\n\n[[5]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -2.9006, Lag order = 4, p-value = 0.2088\nalternative hypothesis: stationary\n\n\n[[6]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -2.3971, Lag order = 4, p-value = 0.4137\nalternative hypothesis: stationary\n\n\n[[7]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -2.8393, Lag order = 4, p-value = 0.2337\nalternative hypothesis: stationary\n\n\n[[8]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -1.6656, Lag order = 4, p-value = 0.7113\nalternative hypothesis: stationary\n\n\n[[9]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -3.132, Lag order = 4, p-value = 0.1147\nalternative hypothesis: stationary\n\n\n[[10]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -3.0487, Lag order = 4, p-value = 0.1485\nalternative hypothesis: stationary\n\n\n[[11]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -2.7396, Lag order = 4, p-value = 0.2743\nalternative hypothesis: stationary\n\n\n[[12]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -2.1174, Lag order = 4, p-value = 0.5275\nalternative hypothesis: stationary\n\n\n[[13]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -2.7746, Lag order = 4, p-value = 0.2601\nalternative hypothesis: stationary\n\n\n\nadf_table &lt;- data.frame(p_value = numeric(length(adf_test)))\n\nfor (i in 1:length(adf_test)) {adf_table[i, \"p_value\"] = round(adf_test[[i]]$p.value,3)\n}\n\nrownames(adf_table)&lt;- c(\"exchange rate\", \n                         \"cpi_au\",    \"cpi_us\", \n                         \"cashrate_au\",  \"cashrate_us\", \n                         \"export_au\", \"export_us\",\n                         \"import_au\",   \"import_us\",\n                         \"realgdp_au\", \"realgdp_us\",\n                         \"unemployemtrate_au\", \"unemployemtrate_us\")\n\ncolnames(adf_table)&lt;- c(\"P-value\")\nprint(adf_table)\n\n                   P-value\nexchange rate        0.551\ncpi_au               0.587\ncpi_us               0.838\ncashrate_au          0.954\ncashrate_us          0.209\nexport_au            0.414\nexport_us            0.234\nimport_au            0.711\nimport_us            0.115\nrealgdp_au           0.149\nrealgdp_us           0.274\nunemployemtrate_au   0.528\nunemployemtrate_us   0.260\n\n#clear that all &gt;0.05 and reject the null that is stationary\n\n\n#take the first difference\ndff_merged_data &lt;- na.omit(merged_data - lag(merged_data))\n\n\n# ADF test\ndff_adf_ &lt;- list()\nfor (i in 1:13) {\n  dff_adf_result = adf.test(dff_merged_data[,i], k = 4)\n  dff_adf_[[i]] &lt;- dff_adf_result\n}\n\nWarning in adf.test(dff_merged_data[, i], k = 4): p-value smaller than printed\np-value\n\nWarning in adf.test(dff_merged_data[, i], k = 4): p-value smaller than printed\np-value\n\n# View the ADF test results\ndff_adf_table &lt;- data.frame(p_value = numeric(length(dff_adf_)))\n\n# Fill in the data frame with the test results\nfor (i in 1:length(dff_adf_)) {\n  dff_adf_table[i, \"p_value\"] = round(dff_adf_[[i]]$p.value,3)\n\n}\nrownames(dff_adf_table)&lt;- c(\"exchange rate\",\n                         \"cpi_au\",    \"cpi_us\", \n                         \"cashrate_au\",  \"cashrate_us\", \n                         \"export_au\", \"export_us\",\n                         \"import_au\",   \"import_us\",\n                         \"realgdp_au\", \"realgdp_us\",\n                         \"unemployemtrate_au\", \"unemployemtrate_us\")\n\ncolnames(dff_adf_table)&lt;- c(\"P-value\")\nprint(dff_adf_table)\n\n                   P-value\nexchange rate        0.035\ncpi_au               0.442\ncpi_us               0.279\ncashrate_au          0.038\ncashrate_us          0.019\nexport_au            0.052\nexport_us            0.024\nimport_au            0.010\nimport_us            0.017\nrealgdp_au           0.034\nrealgdp_us           0.010\nunemployemtrate_au   0.023\nunemployemtrate_us   0.021\n\n\n\n#take the second difference \ndff_dff_data &lt;- subset(dff_merged_data, select = -c(realgdp_us))\n\n# Create a new dataset with the remaining variables\n\ndff_dff_merged_data &lt;- na.omit(dff_dff_data- lag(dff_dff_data)) \n\n\ndff_dff_adf_ &lt;- list()\nfor (i in 1:12) {\n  dff_dff_adf_result = adf.test(dff_dff_merged_data[,i], k = 4)\n  dff_dff_adf_[[i]] &lt;- dff_dff_adf_result\n}\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\n# View the ADF test results\ndff_dff_adf_table &lt;- data.frame(p_value = numeric(length(dff_dff_adf_)))\n\n# Fill in the data frame with the test results\nfor (i in 1:length(dff_dff_adf_)) {\n  dff_dff_adf_table[i, \"p_value\"] = round(dff_dff_adf_[[i]]$p.value,3)\n\n}\nrownames(dff_dff_adf_table)&lt;- c(\"exchange rate\", \n                         \"cpi_au\",    \"cpi_us\", \n                         \"cashrate_au\",  \"cashrate_us\", \n                         \"export_au\", \"export_us\",\n                         \"import_au\",   \"import_us\",\n                         \"realgdp_au\",\n                         \"unemployemtrate_au\", \"unemployemtrate_us\")\n\ncolnames(dff_dff_adf_table)&lt;- c(\"P-value\")\nprint(dff_dff_adf_table)\n\n                   P-value\nexchange rate         0.01\ncpi_au                0.01\ncpi_us                0.01\ncashrate_au           0.01\ncashrate_us           0.01\nexport_au             0.01\nexport_us             0.01\nimport_au             0.01\nimport_us             0.01\nrealgdp_au            0.01\nunemployemtrate_au    0.01\nunemployemtrate_us    0.01\n\n\n\\[\\begin{align}\nY =\\begin{pmatrix}\ny_{crateau_,1}&  y_{rgdpau_,1}&  y_{cpiau_,1}&  y_{unemrau_,1}&  y_{imporau_,1}&  y_{exporau_,1}&  y_{crateus_,1}&  y_{rgdpus_,1}&  y_{cpius_,1}&  y_{unemrus_,1}&  y_{imporus_,1}&  y_{exporus_,1}\\\\\ny_{crateau_,2}&  y_{rgdpau_,2}&  y_{cpiau_,2}&  y_{unemrau_,2}&  y_{imporau_,2}&  y_{exporau_,2}&  y_{crateus_,2}&  y_{rgdpus_,2}&  y_{cpius_,2}&  y_{unemrus_,2}&  y_{imporus_,2}&  y_{exporus_,2}\\\\ \\ \\vdots & \\vdots & \\vdots  & \\vdots & \\vdots & \\vdots& \\vdots& \\vdots& \\vdots& \\vdots& \\vdots & \\vdots\\\\\n\ny_{crateau_,T}&  y_{rgdpau_,T}&  y_{cpiau_,T}&  y_{unemrau_,T}&  y_{imporau_,T}&  y_{exporau_,T}&  y_{crateus_,T}&  y_{rgdpus_,T}&  y_{cpius_,T}&  y_{unemrus_,T}&  y_{imporus_,T}&  y_{exporus_,T}\n\\end{pmatrix}\n\\end{align}\\]"
  }
]