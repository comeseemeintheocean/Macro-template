[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Exchange Rate Forecasting Using Bayesian VARs Model",
    "section": "",
    "text": "Abstract. This research report explores how Bayesian VARs model predict AUD/USD exchange rate. Keywords. Bayesian Vars, Exchange rate, Forecasting, Minnesota Prior, Laplace distribution"
  },
  {
    "objectID": "index.html#a-simple-example",
    "href": "index.html#a-simple-example",
    "title": "Title of your work",
    "section": "A Simple Example",
    "text": "A Simple Example"
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Title of your work",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "index.html#data-and-variables",
    "href": "index.html#data-and-variables",
    "title": "Exchange rate forecasting using Bayesian VARs model",
    "section": "Data and variables",
    "text": "Data and variables\nTo better forecast the change in the exchange rate, the 12 variables are selected as follows which contain both domestic and US economic indicators that affect the exchange rate in different ways.\nReal GDP and interest rates have a significant effect on the exchange rate, a higher realGDP and interest rate in Australia may increase the demand for AUD, which will lead to an appreciation of AUD and a rise in the AUD/USD exchange rate. A higher CPI indicates a lower purchasing power relative to foreign currency which may lead to a depreciation of the domestic currency. The unemployment rate can in some way represent business activity and a country with a high unemployment rate will lower the attractiveness for foreign investors and weaken the domestic currency competitiveness in the currency market. The balance of trade, which is the difference between exports and imports, also can influence the demand for its currency, a trade surplus in AUD may increase the demand for AUD dollar.\n\n\\(erate_{t}\\): AUD/USD exchange rate\nAUS economic indicators\n\n\\(crateau_{t}\\): The Cash Rate Target, Australia\n\\(rgdpau_{t}\\): The Real Gross Domestic Product, Australia\n\\(cpiau_{t}\\): The Consumer Price Index, Australia\n\\(unemrau_{t}\\): The Unemployment rate, Australia\n\\(imporau_{t}\\): The Imports of Goods and Services, Australia\n\\(exporau_{t}\\): The Exports of Goods and Services, Australia\n\nUS economic indicators\n\n\\(crateus_{t}\\): The Federal Funds Effective Rate, United States\n\\(rgdpus_{t}\\): The Real Gross Domestic Product, United States\n\\(cpius_{t}\\): The Consumer Price Index, United States\n\\(unemrus_{t}\\): The Unemployment rate, United States\n\\(imporus_{t}\\): The Imports of Goods and Services, United States\n\\(exporus_{t}\\): The Exports of Goods and Services, United States\n\n\n\nData cleaning\nFor the data cleaning part, most data for AUS is from Reserve Bank of Australia (RBA) and Australian Bureau of Statistics (ABS), and data for the US is from FRED, the dataset spans from 1990 Q1 to 2023 Q4, comprising 136 observations. To better fit the model, the data has been transformed to ‘quarter’ to ensure that seasonality effects are removed and logged transformations have been applied to most data except exchange rate and cash rate to reducing outlier effects.\n\nVisualisation of data\nPlot the variables to see the patterns of data. It shows from the plots that the exchange rate and cash rate for the US fluctuate over time, the cash rate and unemployment for AU show a downward trend and all other variables have a clear upward trend, with the exports、imports, and GDP for both countries have a clear drop during the COVID-19 period.\n\n\n\n\n\nSince most variables show a non-stationary pattern. To determine whether a unit root is present in a time series dataset, the ADF test will be conducted below.\n\n\nAugmented Dickey-Fuller test for log transformed variables except exchange rates and cash rates.\nFrom the plot we can observe all ACF plots have a high degree of persistence over time, indicating there is significant autocorrelation in the time series data.\n\n\n\n\n\nBelow is the p-value of each variable and only the cash rate for AUS has a p-value less than 0.05 which indicates that \\(crateau_{t}\\) is stationary.\n\n\n                   P-value\nexchange rate        0.736\ncpi_au               0.214\ncpi_us               0.450\ncashrate_au          0.010\ncashrate_us          0.270\nexport_au            0.496\nexport_us            0.365\nimport_au            0.189\nimport_us            0.603\nrealgdp_au           0.961\nrealgdp_us           0.633\nunemployemtrate_au   0.354\nunemployemtrate_us   0.358\n\n\nBelow is the ADF test result for all non-stationary data taking the first difference. All variables in the first differences are stationary as the null hypothesis of non-stationary can be rejected.\n\n\n                   P-value\nexchange rate        0.010\ncpi_au               0.027\ncpi_us               0.024\ncashrate_us          0.010\nexport_au            0.010\nexport_us            0.010\nimport_au            0.010\nimport_us            0.010\nrealgdp_au           0.010\nrealgdp_us           0.010\nunemployemtrate_au   0.010\nunemployemtrate_us   0.010\n\n\nIt can be concluded that all variables are integrated at 1 with \\(crateau_{t}\\) being the only stationary so the first difference should be taken to keep the time series stationary."
  },
  {
    "objectID": "macro_quarto.html",
    "href": "macro_quarto.html",
    "title": "macro_quarto",
    "section": "",
    "text": "library(fredr)\nlibrary(readrba)\nlibrary(readabs)\n\nEnvironment variable 'R_READABS_PATH' is unset. Downloaded files will be saved in a temporary directory.\nYou can set 'R_READABS_PATH' at any time. To set it for the rest of this session, use\n    Sys.setenv(R_READABS_PATH = &lt;path&gt;)\n\nlibrary(quantmod)\n\nLoading required package: xts\n\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nLoading required package: TTR\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\nfredr_set_key(\"75b470c4883ecfd5a7b4185f30437bd0\")"
  },
  {
    "objectID": "Test.html",
    "href": "Test.html",
    "title": "test",
    "section": "",
    "text": "# log transformation of data\ncpi_au &lt;- log(cpi_au)\ncpi_us &lt;- log(cpi_us)\nrgdp_au &lt;- log(rgdp_au)\nrgdp_us &lt;- log(rgdp_us)\nimpor_au &lt;- log(impor_au)\nimpor_us&lt;- log(impor_us)\nexpor_au &lt;- log(expor_au)\nexpor_us&lt;- log(expor_us)\ngprice &lt;- log(gprice)\n\n\n\n\n\n\n\n\n\n\nx_varibales &lt;-  na.omit(merge(gprice,\n                            cpi_au, cpi_us, \n                            crate_au, crate_us, \n                            expor_au, expor_us,  \n                            impor_au, impor_us, \n                            rgdp_au, rgdp_us,\n                            unemr_au, unemr_us))\ncolnames(x_varibales)   = c(\"gold price\", \n                         \"cpi_au\",    \"cpi_us\", \n                         \"cashrate_au\",  \"cashrate_us\", \n                         \"export_au\", \"export_us\",\n                         \"import_au\",   \"import_us\",\n                         \"realgdp_au\", \"realgdp_us\",\n                         \"unemployemtrate_au\", \"unemployemtrate_us\")\n\n\n# Compute correlation matrix\ncorrelation_matrix &lt;- cor(merged_data)\n\n# Find the row number corresponding to \"erate\"\nerate_row &lt;- which(rownames(correlation_matrix) == \"erate\")\n\n# Extract correlations between erate and other variables\ncorrelations_erate &lt;- correlation_matrix[erate_row, names(merged_data) != \"erate\"]\n\n# Print correlation values\nprint(correlations_erate)\n\n     exchange rate cpi_au cpi_us cashrate_au cashrate_us export_au export_us\n     import_au import_us realgdp_au realgdp_us unemployemtrate_au\n     unemployemtrate_us\n\n\n\nAugmented Dickey-Fuller test for log transformed variables except exchange rate and cash rate.\n\npar(mfcol = c(3, 2), mar=c(2,2,2,2))\nfor (i in 1:6){\nacf = acf(merged_data[,i], plot = FALSE)[1:20]\nplot(acf, main = \"\")\ntitle(main = paste(colnames(merged_data)[i]), line = 0.5)\n}\n\n\n\npar(mfrow = c(3, 2), mar=c(2,2,2,2))\nfor (i in 7:13){\nacf = acf(merged_data[,i], plot = FALSE)[1:20]\nplot(acf, main = \"\")\ntitle(main = paste(colnames(merged_data)[i]), line = 0.5)\n}\n\n\n\n\n\n\n\n\nadf_test &lt;- list()\nfor (i in 1:13) {\n  adf_result = adf.test(merged_data[,i], k = 4)\n  adf_test[[i]] &lt;- adf_result\n}\n\nprint(adf_test)\n\n[[1]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -2.0604, Lag order = 4, p-value = 0.5507\nalternative hypothesis: stationary\n\n\n[[2]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -1.9709, Lag order = 4, p-value = 0.5871\nalternative hypothesis: stationary\n\n\n[[3]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -1.355, Lag order = 4, p-value = 0.8378\nalternative hypothesis: stationary\n\n\n[[4]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -0.84089, Lag order = 4, p-value = 0.9536\nalternative hypothesis: stationary\n\n\n[[5]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -2.9006, Lag order = 4, p-value = 0.2088\nalternative hypothesis: stationary\n\n\n[[6]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -2.3971, Lag order = 4, p-value = 0.4137\nalternative hypothesis: stationary\n\n\n[[7]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -2.8393, Lag order = 4, p-value = 0.2337\nalternative hypothesis: stationary\n\n\n[[8]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -1.6656, Lag order = 4, p-value = 0.7113\nalternative hypothesis: stationary\n\n\n[[9]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -3.132, Lag order = 4, p-value = 0.1147\nalternative hypothesis: stationary\n\n\n[[10]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -3.0487, Lag order = 4, p-value = 0.1485\nalternative hypothesis: stationary\n\n\n[[11]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -2.7396, Lag order = 4, p-value = 0.2743\nalternative hypothesis: stationary\n\n\n[[12]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -2.1174, Lag order = 4, p-value = 0.5275\nalternative hypothesis: stationary\n\n\n[[13]]\n\n    Augmented Dickey-Fuller Test\n\ndata:  merged_data[, i]\nDickey-Fuller = -2.7746, Lag order = 4, p-value = 0.2601\nalternative hypothesis: stationary\n\n\n\nadf_table &lt;- data.frame(p_value = numeric(length(adf_test)))\n\nfor (i in 1:length(adf_test)) {adf_table[i, \"p_value\"] = round(adf_test[[i]]$p.value,3)\n}\n\nrownames(adf_table)&lt;- c(\"exchange rate\", \n                         \"cpi_au\",    \"cpi_us\", \n                         \"cashrate_au\",  \"cashrate_us\", \n                         \"export_au\", \"export_us\",\n                         \"import_au\",   \"import_us\",\n                         \"realgdp_au\", \"realgdp_us\",\n                         \"unemployemtrate_au\", \"unemployemtrate_us\")\n\ncolnames(adf_table)&lt;- c(\"P-value\")\nprint(adf_table)\n\n                   P-value\nexchange rate        0.551\ncpi_au               0.587\ncpi_us               0.838\ncashrate_au          0.954\ncashrate_us          0.209\nexport_au            0.414\nexport_us            0.234\nimport_au            0.711\nimport_us            0.115\nrealgdp_au           0.149\nrealgdp_us           0.274\nunemployemtrate_au   0.528\nunemployemtrate_us   0.260\n\n#clear that all &gt;0.05 and reject the null that is stationary\n\n\n#take the first difference\ndff_merged_data &lt;- na.omit(merged_data - lag(merged_data))\n\n\n# ADF test\ndff_adf_ &lt;- list()\nfor (i in 1:13) {\n  dff_adf_result = adf.test(dff_merged_data[,i], k = 4)\n  dff_adf_[[i]] &lt;- dff_adf_result\n}\n\nWarning in adf.test(dff_merged_data[, i], k = 4): p-value smaller than printed\np-value\n\nWarning in adf.test(dff_merged_data[, i], k = 4): p-value smaller than printed\np-value\n\n# View the ADF test results\ndff_adf_table &lt;- data.frame(p_value = numeric(length(dff_adf_)))\n\n# Fill in the data frame with the test results\nfor (i in 1:length(dff_adf_)) {\n  dff_adf_table[i, \"p_value\"] = round(dff_adf_[[i]]$p.value,3)\n\n}\nrownames(dff_adf_table)&lt;- c(\"exchange rate\",\n                         \"cpi_au\",    \"cpi_us\", \n                         \"cashrate_au\",  \"cashrate_us\", \n                         \"export_au\", \"export_us\",\n                         \"import_au\",   \"import_us\",\n                         \"realgdp_au\", \"realgdp_us\",\n                         \"unemployemtrate_au\", \"unemployemtrate_us\")\n\ncolnames(dff_adf_table)&lt;- c(\"P-value\")\nprint(dff_adf_table)\n\n                   P-value\nexchange rate        0.035\ncpi_au               0.442\ncpi_us               0.279\ncashrate_au          0.038\ncashrate_us          0.019\nexport_au            0.052\nexport_us            0.024\nimport_au            0.010\nimport_us            0.017\nrealgdp_au           0.034\nrealgdp_us           0.010\nunemployemtrate_au   0.023\nunemployemtrate_us   0.021\n\n\n\n#take the second difference \ndff_dff_data &lt;- subset(dff_merged_data, select = -c(realgdp_us))\n\n# Create a new dataset with the remaining variables\n\ndff_dff_merged_data &lt;- na.omit(dff_dff_data- lag(dff_dff_data)) \n\n\ndff_dff_adf_ &lt;- list()\nfor (i in 1:12) {\n  dff_dff_adf_result = adf.test(dff_dff_merged_data[,i], k = 4)\n  dff_dff_adf_[[i]] &lt;- dff_dff_adf_result\n}\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\nWarning in adf.test(dff_dff_merged_data[, i], k = 4): p-value smaller than\nprinted p-value\n\n# View the ADF test results\ndff_dff_adf_table &lt;- data.frame(p_value = numeric(length(dff_dff_adf_)))\n\n# Fill in the data frame with the test results\nfor (i in 1:length(dff_dff_adf_)) {\n  dff_dff_adf_table[i, \"p_value\"] = round(dff_dff_adf_[[i]]$p.value,3)\n\n}\nrownames(dff_dff_adf_table)&lt;- c(\"exchange rate\", \n                         \"cpi_au\",    \"cpi_us\", \n                         \"cashrate_au\",  \"cashrate_us\", \n                         \"export_au\", \"export_us\",\n                         \"import_au\",   \"import_us\",\n                         \"realgdp_au\",\n                         \"unemployemtrate_au\", \"unemployemtrate_us\")\n\ncolnames(dff_dff_adf_table)&lt;- c(\"P-value\")\nprint(dff_dff_adf_table)\n\n                   P-value\nexchange rate         0.01\ncpi_au                0.01\ncpi_us                0.01\ncashrate_au           0.01\ncashrate_us           0.01\nexport_au             0.01\nexport_us             0.01\nimport_au             0.01\nimport_us             0.01\nrealgdp_au            0.01\nunemployemtrate_au    0.01\nunemployemtrate_us    0.01\n\n\n\\[\\begin{align}\nY =\\begin{pmatrix}\ny_{crateau_,1}&  y_{rgdpau_,1}&  y_{cpiau_,1}&  y_{unemrau_,1}&  y_{imporau_,1}&  y_{exporau_,1}&  y_{crateus_,1}&  y_{rgdpus_,1}&  y_{cpius_,1}&  y_{unemrus_,1}&  y_{imporus_,1}&  y_{exporus_,1}\\\\\ny_{crateau_,2}&  y_{rgdpau_,2}&  y_{cpiau_,2}&  y_{unemrau_,2}&  y_{imporau_,2}&  y_{exporau_,2}&  y_{crateus_,2}&  y_{rgdpus_,2}&  y_{cpius_,2}&  y_{unemrus_,2}&  y_{imporus_,2}&  y_{exporus_,2}\\\\ \\ \\vdots & \\vdots & \\vdots  & \\vdots & \\vdots & \\vdots& \\vdots& \\vdots& \\vdots& \\vdots& \\vdots & \\vdots\\\\\n\ny_{crateau_,T}&  y_{rgdpau_,T}&  y_{cpiau_,T}&  y_{unemrau_,T}&  y_{imporau_,T}&  y_{exporau_,T}&  y_{crateus_,T}&  y_{rgdpus_,T}&  y_{cpius_,T}&  y_{unemrus_,T}&  y_{imporus_,T}&  y_{exporus_,T}\n\\end{pmatrix}\n\\end{align}\\]"
  },
  {
    "objectID": "index.html#augmented-dickey-fuller-test-for-log-transformed-variables-except-exchange-rate-and-cash-rate.",
    "href": "index.html#augmented-dickey-fuller-test-for-log-transformed-variables-except-exchange-rate-and-cash-rate.",
    "title": "Title of your work",
    "section": "Augmented Dickey-Fuller test for log transformed variables except exchange rate and cash rate.",
    "text": "Augmented Dickey-Fuller test for log transformed variables except exchange rate and cash rate.\n\n\n\n\n\n\n\n                   P-value\nexchange rate        0.736\ncpi_au               0.214\ncpi_us               0.450\ncashrate_au          0.010\ncashrate_us          0.270\nexport_au            0.496\nexport_us            0.365\nimport_au            0.189\nimport_us            0.603\nrealgdp_au           0.953\nrealgdp_us           0.633\nunemployemtrate_au   0.354\nunemployemtrate_us   0.358\n\n\n\n\n                   P-value\nexchange rate        0.010\ncpi_au               0.027\ncpi_us               0.024\ncashrate_us          0.010\nexport_au            0.010\nexport_us            0.010\nimport_au            0.010\nimport_us            0.010\nrealgdp_au           0.010\nrealgdp_us           0.010\nunemployemtrate_au   0.010\nunemployemtrate_us   0.010"
  },
  {
    "objectID": "index.html#model-and-hypotheses",
    "href": "index.html#model-and-hypotheses",
    "title": "Exchange rate forecasting using Bayesian VARs model",
    "section": "Model and Hypotheses",
    "text": "Model and Hypotheses\nIn this research, the VAR(p) model will be applied to forecast the AUD/USD exchange rate, below is the basic model that is used in this research.\n\nThe basic VAR(p) model\n\\[\\begin{aligned}\ny_{t}=\\mu_{0}+A_{1}y_{t-1}+\\cdots+A_{p}y_{t-p}+\\epsilon_{t} \\\\\n\\epsilon_{t}|Y_{t-1}\\sim iid(0_{12},\\Sigma)\n\\end{aligned}\\]\nWhere N = 12 and \\(y_{t}\\) is a vector of 12 variables.\n\\[\\begin{aligned}\ny_{t}=\\begin{pmatrix}\ncrateau_{t} \\\\\nrgdpau_{t}\\\\\ncpiau_{t} \\\\\nunemrau_{t}\\\\\nimporau_{t} \\\\\nexporau_{t} \\\\\ncrateus_{t} \\\\\nrgdpus_{t} \\\\\ncpius_{t} \\\\\nunemrus_{t} \\\\\nimporus_{t}\\\\\nexporus_{t}\\\\\n\n\\end{pmatrix}\n\n\\end{aligned}\\]\n\n\nThe Matrix notation\n\\[\\begin{align}\nY =XA+E\\\\\nE|X\\sim \\mathcal{MN}_{T\\times N}(0, \\Sigma, I_T)\\\\\nY|X,A,\\Sigma\\sim \\mathcal{MN}_{T\\times N} (XA, \\Sigma, I_T)\n\\end{align}\\]\nWhere \\(Y\\) is a \\(T\\times 12\\) Matrix, \\(X\\) is a \\(T\\times(1+p\\times12)\\), \\(A\\) is a \\((1+p\\times12)\\times12\\) matrix that contains \\(\\mu_{0}\\) and vectors of the autoregressive slope parameters and \\(E\\) is a \\(T\\times12\\) matrix contains vetors of error terms.\nFor further research, we may use the predictive density function like 1-period forecast and forecast with Bayesian VARS."
  },
  {
    "objectID": "index.html#model-specification",
    "href": "index.html#model-specification",
    "title": "Exchange rate forecasting using Bayesian VARs model",
    "section": "Model specification",
    "text": "Model specification\nThe use of fiscal policy to stimulate or regulate the economy follows the Keynesian approach generally practiced around the world (but especially in developing countries) to navigate economies through downturns or potential episodes of overheating, particularly in the short-run. The proposed model aims to investigate the effectiveness of these fiscal measures in managing growth and unemployment.\nEstimation proceeds through the following reduced form model:\n\\[\n\\begin{align}\nY &= XA + U\\\\\nU| X &\\sim _{iid} MN_{T\\times N}( 0, \\Sigma, \\Omega)\\\\\n\\Sigma &= B_0^{-1}B_0^{-1'}\n\\end{align}\n\\] where matrix \\(Y\\) contains vectors of endogenous variables \\(y_t\\):\n\\[y_t=\\begin{pmatrix} unemp_t &= \\text{unemployment rate}\n\\\\ realgdp_t &= \\text{real GDP}\n\\\\ totaltax_t  &= \\text{tax revenue}\n\\\\ nontax_t  &= \\text{non-tax revenue}\n\\\\ pubinv_t  &= \\text{government gross fixed capital formation}\n\\\\ pubtrans_t  &= \\text{social assitance and benefits payments}\n\\\\ pubcons_t  &= \\text{government final consumption}\n\\\\ cashrate_t  &= \\text{cash rate target}\n\\\\ M3_t  &= \\text{M3 money supply}\n\\end{pmatrix}\\]\nand \\(B_0^{-1}=B\\) is the matrix of contemporaneous effects between variables."
  },
  {
    "objectID": "index.html#estimation-and-identification",
    "href": "index.html#estimation-and-identification",
    "title": "Exchange rate forecasting using Bayesian VARs model",
    "section": "Estimation and identification",
    "text": "Estimation and identification\n\nBasic model\nFor the basic model, the column-wise covariance matrix is set as \\(\\Omega=I_N\\). The likelihood function is expressed as:\n\\[P(Y,X|A,\\Sigma) \\propto det(\\Sigma)^{-\\frac{T}{2}} exp \\left\\{-\\frac{1}{2} tr \\left[ \\Sigma^{-1}(Y-XA)'(Y-XA) \\right] \\right\\}\\\\\\] \\[=det(\\Sigma)^{-\\frac{T}{2}} exp \\left\\{-\\frac{1}{2} tr \\left[ \\Sigma^{-1}(A-\\hat{A})'X'X(A-\\hat{A}) \\right] \\right\\} exp \\left\\{-\\frac{1}{2} tr \\left[\\Sigma^{-1}(Y-X \\hat{A})'(Y-X \\hat{A}) \\right] \\right\\}\\]\nwhere the maximum likelihood estimators are expressed as:\n\\[\\hat{A} = (X'X)^{-1}X'Y \\] \\[\\hat{\\Sigma} = \\frac{1}{T} (Y-X \\hat{A})'(Y-X \\hat{A})\\]\nThe prior for \\(A\\) and \\(\\Sigma\\) is assumed to be a matrix-normal inverse Wishart distribution that follows the Minnesota specification of Doan, Litterman & Sims (1984):\n\\[p(A,\\Sigma) =MNIW(\\underline{A},\\underline{S},\\underline{V},\\underline{\\nu})\\]\n\\[A|\\Sigma\\sim MN_{K\\times N}(\\underline{A},\\Sigma,\\underline{V})\\] \\[\\Sigma\\sim IW_N(\\underline{S},\\underline{\\nu})\\]\nwhere:\n\\[\\underline{A} = [0_{N \\times 1} \\quad I_N \\quad 0_{N \\times (p-1)N}]'\\] \\[\\underline{V} = diag([\\kappa_2 \\quad \\kappa_1 (p^{-2} \\otimes I_N)])\\]\nThis leads to the following posterior distribution, from which the basic reduced form model will be estimated:\n\\[P(A|Y,X,\\Sigma)=MN_{K\\times N}(\\bar{A},\\Sigma,\\bar{V})\\] \\[P(\\Sigma|Y,X)=IW_N(\\bar{S},\\bar{\\nu})\\\\\\]\n\\[\\bar{V}=(X'X+\\underline{V}^{-1})^{-1}\\] \\[\\bar{A}=\\bar{V}(X'Y+\\underline{V}^{-1}\\underline{A})\\] \\[\\bar{\\nu}=T+\\underline{\\nu}\\] \\[\\bar{S}=\\underline{S}+Y'Y+\\underline{A}'\\underline{V}^{-1}\\underline{A}-\n\\bar{A}'\\bar{V}^{-1}\\bar{A}\\]"
  },
  {
    "objectID": "index.html#forecasting-with-bayesian-vars",
    "href": "index.html#forecasting-with-bayesian-vars",
    "title": "Exchange rate forecasting using Bayesian VARs model",
    "section": "Forecasting with Bayesian VARs",
    "text": "Forecasting with Bayesian VARs\nThe Modelling Framework"
  },
  {
    "objectID": "index.html#estimation-procedure-for-the-baseline-model",
    "href": "index.html#estimation-procedure-for-the-baseline-model",
    "title": "Exchange rate forecasting using Bayesian VARs model",
    "section": "Estimation Procedure for the Baseline Model",
    "text": "Estimation Procedure for the Baseline Model\nThe baseline model is as follows:\n\\[\\begin{align}\nY &= XA + U \\\\\nY|X,A,\\Sigma &\\sim MN_{T \\times N} (XA, \\Sigma, I_T)\n\\end{align}\\]\nThis implies the following form for the kernel of the likelihood function:\n\\[\\begin{align}\nL(A,\\Sigma|Y,X) \\propto det(\\Sigma)^{-\\frac{T}{2}}exp(-\\frac{1}{2}tr[\\Sigma^{-1}(Y-XA)'(Y-XA)])\n\\end{align}\\]"
  },
  {
    "objectID": "index.html#the-baseline-model",
    "href": "index.html#the-baseline-model",
    "title": "Exchange rate forecasting using Bayesian VARs model",
    "section": "The Baseline Model",
    "text": "The Baseline Model\nThe model used for the forecasting experiment is a VAR(p) model:\n\\[\\begin{aligned}\n& y_t  =\\mu_0+A_1 y_{t-1}+\\cdots+A_p y_{t-p}+\\epsilon_t \\\\ & \\epsilon_t \\mid  Y_{t-1}  \\sim i i d \\mathcal{N}_N\\left(\\mathbf{0}_N, \\Sigma\\right)\n\\end{aligned}\\]\nWhere \\(N=11\\) and \\(y_t\\) is the vector of 11 variables:\nThe model can also be written in matrix notation:\n\\[\\begin{aligned}\nY & =X A+E \\\\E \\mid X & \\sim \\mathcal{M N} _{T \\times N}\\left(\\mathbf{0}_{T \\times N}, \\Sigma, I_T\\right)\n\\end{aligned}\\]\nWhere \\(Y\\) is a \\(T\\times11\\) matrix, \\(X\\) is a \\(T\\times(1+(11\\times p))\\), \\(A\\) is a \\((1+(11\\times p))\\times 11\\) matrix that contains the relationships between the variables and \\(E\\) is a \\(T\\times11\\). \\(p\\) is 1 and \\(T\\) is 135."
  },
  {
    "objectID": "index.html#the-basic-model",
    "href": "index.html#the-basic-model",
    "title": "Exchange Rate Forecasting Using Bayesian VARs Model",
    "section": "The basic model",
    "text": "The basic model\n\\[\\begin{align}\nY &=XA+E\\\\\nE|X&\\sim \\mathcal{MN}_{T\\times N}(0, \\Sigma, I_T)\\\\\nY|X,A,\\Sigma&\\sim \\mathcal{MN}_{T\\times N} (XA, \\Sigma, I_T)\n\\end{align}\\]\nWhere \\(Y\\) is a \\(T\\times 13\\) Matrix, \\(X\\) is a \\(T\\times(1+p\\times13)\\), \\(A\\) is a \\((1+p\\times13)\\times13\\) matrix that contains \\(\\mu_{0}\\) and vectors of the autoregressive slope parameters and \\(E\\) is a \\(T\\times13\\) matrix contains vetors of error terms.\nThe kernel of the likelihood function:\n\\[\\begin{align}\nL(A,\\Sigma|Y,X) \\propto det(\\Sigma)^{-\\frac{T}{2}}exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}(Y-XA)'(Y-XA)]\\}\n\\end{align}\\]\nThe basic model is based on Natural-conjugate prior distribution, where the \\(A\\) follows a Matrix-variate Normal distribution and \\(\\Sigma\\) follows an Inverse Wishart distribution.\n\\[\\begin{align}\np(A,\\Sigma) &= p(A|\\Sigma)p(\\Sigma) \\\\\nA|\\Sigma &\\sim \\mathcal{MN}_{K \\times N}(\\underline{A},\\Sigma,\\underline{V}) \\\\\n\\Sigma &\\sim \\mathcal{IW}_N(\\underline{S},\\underline{\\nu})\n\\end{align}\\]\nThe Minnesota prior is typically a good choice for specifying priors in BVAR model especially when the model involves many macroeconomic variables. It assumes the variables follow a random walk and it is suitable for unit root non-stationary variables such as in our case, most variables are integrated at 1 at the 5% significance level of the ADF test, where:\n\\[\\begin{align}\n\\underline{A} &= \\begin{bmatrix}0_{N \\times 1} & I_{N} & 0_{N \\times (p-1)N}\\end{bmatrix}'\\\\\n\n\\underline{V} &= diag( \\begin{bmatrix} \\kappa_2 & \\kappa_1(p^{-2}\\otimes I_N') \\end{bmatrix})\n\n\\end{align}\\]\nThe prior mean \\(\\underline{A}\\) for the first lag of each variable (the identity matrix portion) is one, while all other coefficients including intercepts, are zeroes. For the column-specific prior covariance \\(\\underline{V}\\), two shrinkage hyper-parameters \\(\\kappa_1\\) and \\(\\kappa_2\\) represent the overall shrinkage level for slopes and constant terms respectively.\nFor posterior distribution, the kernel of the posterior distribution takes the form of the product of the likelihood and the prior distributions.\n\\[\\begin{align*}\np(A,\\Sigma|Y,X) &\\propto L(A,\\Sigma|Y,X)p(A,\\Sigma) \\\\\n&= L(A,\\Sigma|Y,X)p(A|\\Sigma)p(\\Sigma)\n\\end{align*}\\]\n\\[\\begin{align}\np(A,\\Sigma|Y,X) &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\\\\n&\\times exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}(Y-XA)'(Y-XA)]\\} \\\\\n&\\times \\det(\\Sigma)^{-\\frac{N+K+\\underline{v}+1}{2}} \\\\\n&\\times exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}(A-\\underline{A}) \\underline{V}^{-1}(A-\\underline{A})]\\} \\\\\n&\\times exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}\\underline{S}]\\}\n\\end{align}\\]\nThe kernel can be represent as the normal-inverse Wishart distribution and we can get the following full conditional joint posterior distribution: \n\\[\\begin{align}\np(A|Y,X,\\Sigma) &= \\mathcal{MN}_{K \\times N}(\\bar{A}, \\Sigma, \\bar{V}) \\\\\np(\\Sigma|Y,X) &= \\mathcal{IW}_N(\\bar{S},\\bar{\\nu}) \\\\\n\\\\\n\\bar{V} &= (X'X + \\underline{V}^{-1})^{-1} \\\\\n\\bar{A} &= \\bar{V}(X'Y + \\underline{V}^{-1}\\underline{A}) \\\\\n\\bar{\\nu} &= T + \\underline{\\nu} \\\\\n\\bar{S} &= \\underline{S} + Y'Y + \\underline{A}'\\underline{V}^{-1}\\underline{A} - \\bar{A}'\\bar{V}^{-1}\\bar{A} \\\\\n\n\\end{align}\\]"
  },
  {
    "objectID": "index.html#the-extended-model",
    "href": "index.html#the-extended-model",
    "title": "Exchange Rate Forecasting Using Bayesian VARs Model",
    "section": "The extended model",
    "text": "The extended model\nThe extended model will be built based on the the change in distribution of the error to Laplace distribution instead of the normally distributed errors assumption. The Laplace distribution is suitable for describing financial anomalies due to its sharp peaks and thick tails and the use of this distribution improves the robustness of the model to anomalies and is particularly suitable for financial time series. As our variables are most financial time series data, a Laplace distribution is more suitable to apply to our error term.\nFollowing Eltoft,Kim, and Lee 2006b, for covariance with a general Kronecker structure, if each \\({\\lambda_t}\\) has an independent exponential distribution with mean \\({\\alpha}\\), then marginally \\({U_t}\\) has a multivariate Laplace distribution with mean vector 0 and covariance matrix \\({\\alpha\\Sigma}\\).\n\\[\\begin{align}\nU_t &\\sim \\text{Laplace}(0, \\alpha\\Sigma) \\\\\nU_t | \\lambda_t &\\sim \\mathcal{MN}(0, \\Sigma, \\lambda_t I_T) \\\\\n\\lambda_t &\\sim \\text{Exponential}(\\frac{1}{\\alpha})\n\\end{align}\\]\nThe kernel of the likelihood function:\n\\[\\begin{align}\nL(A,\\Sigma,\\lambda_t|Y,X) &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\det(\\lambda_t I_T)^{-\\frac{N}{2}} exp\\{-\\frac{1}{2} tr[\\Sigma^{-1} (Y-XA)' (\\lambda_t I_T)^{-1} (Y-XA) ]\\}\n\\end{align}\\]\nFor posteriors distribution, \\(A\\), \\(\\Sigma\\) and \\(\\lambda_t\\) can then be derived using the likelihood and the prior distributions as follows:\n\\[\\begin{align}\np(A,\\Sigma|Y,X) &\\propto L(A,\\Sigma,\\lambda_t|Y,X)p(A,\\Sigma) \\\\\n\\\\\n&= \\det(\\Sigma)^{-\\frac{T}{2}} \\det(\\lambda_t I_T)^{-\\frac{N}{2}} exp\\{-\\frac{1}{2} tr[\\Sigma^{-1} (Y-XA)' (\\lambda_t I_T)^{-1} (Y-XA) ]\\} \\\\\n&\\times \\det(\\Sigma)^{-\\frac{N+k+\\underline{\\nu}+1}{2}} exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}(A-\\underline{A})'(\\underline{V})^{-1}(A-\\underline{A})]\\} \\\\\n&\\times exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}\\underline{S}]\\} \\\\\n&= \\det(\\Sigma)^{-\\frac{T+N+K+\\underline{\\nu}+1}{2}} \\det(\\lambda_t I_T)^{-\\frac{N}{2}} \\\\\n&\\times exp\\{-\\frac{1}{2} tr[\\Sigma^{-1}(Y'(\\lambda_t I_T)^{-1}Y - 2A'X'(\\lambda_t I_T)^{-1}Y + A'X'(\\lambda_t I_T)^{-1}XA \\\\\n&+ A'\\underline{V}^{-1}A -2A'\\underline{V}^{-1}\\underline{A} + \\underline{A}'\\underline{V}^{-1}\\underline{A} + \\underline{S})]\\}\n\n\\end{align}\\]\nThe kernel can be rearranged in the form of the Matrix-variate normal-inverse Wishart distribution.\n\\[\n\\begin{align}\np(A,\\Sigma|Y,X) &\\sim \\mathcal{MNIW}(\\bar{A},\\bar{V},\\bar{S},\\bar{\\nu}) \\\\\n&\\\\\n\\bar{V} &= (X'(\\lambda_t I_T)^{-1}X + \\underline{V}^{-1})^{-1} \\\\\n\\bar{A} &= \\bar{V}(X'(\\lambda_t I_T)^{-1}Y + \\underline{V}^{-1}\\underline{A}) \\\\\n\\bar{\\nu} &= T + \\underline{\\nu}\\\\\n\\bar{S} &= Y'(\\lambda_t I_T)^{-1}Y + \\underline{A}'\\underline{V}^{-1}\\underline{A} + \\underline{S} - \\bar{A}'\\bar{V}^{-1}\\bar{A}\n\\end{align}\n\\]\nThe kernel of the fully conditional posterior distribution of \\(\\lambda_t\\) is then derived as follows:\n\\[\\begin{align}\np(\\lambda_t|Y,X,A,\\Sigma) &\\propto L(A,\\Sigma,\\lambda_t|Y,X)p(\\lambda_t) \\\\\n\\\\\n&\\propto \\det(\\lambda_t I_T)^{-\\frac{N}{2}} exp\\{-\\frac{1}{2} tr[\\Sigma^{-1} (Y-XA)' (\\lambda_t I_T)^{-1} (Y-XA) ]\\} \\\\\n&\\times \\frac{1}{\\alpha}exp\\{ -\\frac{1}{\\alpha}\\lambda_t \\}\\\\\n\n&= \\lambda_t^{-\\frac{TN}{2}} exp\\{-\\frac{1}{2}\\frac{1}{\\lambda_t} tr[\\Sigma^{-1}(Y-XA)'(Y-XA)]\\}\\\\\n&\\times exp\\{-\\frac{1}{\\alpha}\\lambda_t \\}\\\\\n\n&= \\lambda_t^{-\\frac{TN}{2}+1-1} exp\\{-\\frac{1}{2}[\\frac{[tr[\\Sigma^{-1}(Y-XA)'(Y-XA)]}{\\lambda_t} +\\frac{2}{\\alpha}\\lambda_t]\\}\n\\end{align}\\]\nThe above expression can be rearranged in the form of a Generalized inverse Gaussian distribution kernel as follows:\n\\[\\begin{align}\n\\lambda_t|Y,A,\\Sigma &\\sim GIG(a,b,p) \\\\\n\\\\\na &=\\frac{2}{\\alpha} \\\\\nb &= tr[\\Sigma^{-1}(Y-XA)'(Y-XA)] \\\\\np &= -\\frac{TN}{2}+1\n\\end{align}\\]"
  },
  {
    "objectID": "index.html#model-extension-t-distributed-errors",
    "href": "index.html#model-extension-t-distributed-errors",
    "title": "Exchange Rate Forecasting Using Bayesian VARs Model",
    "section": "Model Extension: T-Distributed Errors",
    "text": "Model Extension: T-Distributed Errors\nAn alternative specification for the model is to relax the assumption of normally distributed errors. A T-Distribution more closely mirrors the leptokurtosis commonly seen in financial time series and as such it is a good candidate for our model of index volatility.\n\\[\\begin{align}\nU_t &\\sim t_N(0, \\Sigma, \\nu)\n\\end{align}\\]\nFollowing the methodology of Geweke 1993, a T-distribution for the error term can be represented by a scale mixture of normal distributions with a scaling term \\(\\lambda\\) which is Inverse Gamma 2 distributed.\n\\[\\begin{align}\nU|\\lambda &\\sim MN(0, \\Sigma, \\lambda I_T) \\\\\n\\lambda &\\sim IG2( s_{\\lambda}, \\nu_{\\lambda})\n\\end{align}\\]\nUnder this specification, the kernel of the likelihood function takes the following form:\n\\[\\begin{align}\n\nL(A,\\Sigma,\\Lambda|Y,X) &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\det(\\lambda I_T)^{-\\frac{N}{2}} exp(-\\frac{1}{2} tr[\\Sigma^{-1} (Y-XA)' (\\lambda I_T)^{-1} (Y-XA) ])\n\n\\end{align}\\]\nThe posteriors for \\(A\\), \\(\\Sigma\\) and \\(\\lambda\\) can then be derived using the likelihood and the prior distributions. The natural conjugacy of \\(A\\) and \\(\\Sigma\\) is preserved and so the conditional posterior \\(p(A,\\Sigma|Y,X)\\) can be derived as follows.\n\\[\\begin{align}\np(A,\\Sigma|Y,X) &\\propto L(A,\\Sigma,\\lambda|Y,X)p(A,\\Sigma) \\\\\n\\\\\n&= \\det(\\Sigma)^{-\\frac{T}{2}} \\det(\\lambda I_T)^{-\\frac{N}{2}} exp(-\\frac{1}{2} tr[\\Sigma^{-1} (Y-XA)' (\\lambda I_T)^{-1} (Y-XA) ]) \\\\\n&\\times \\det(\\Sigma)^{-\\frac{N+k+\\underline{\\nu}+1}{2}} exp(-\\frac{1}{2}tr[\\Sigma^{-1}(A-\\underline{A})'(\\underline{V})^{-1}(A-\\underline{A})]) \\\\\n&\\times exp(-\\frac{1}{2}tr[\\Sigma^{-1}\\underline{S}]) \\\\\n\\\\\n&= \\det(\\Sigma)^{-\\frac{T+N+K+\\underline{\\nu}+1}{2}} \\det(\\lambda I_T)^{-\\frac{N}{2}} \\\\\n\n&\\times exp(-\\frac{1}{2} tr[\\Sigma^{-1}(Y'(\\lambda I_T)^{-1}Y - 2A'X'(\\lambda I_T)^{-1}Y + A'X'(\\lambda I_T)^{-1}XA \\\\\n\n&+ A'\\underline{V}^{-1}A -2A'\\underline{V}^{-1}\\underline{A} + \\underline{A}'\\underline{V}^{-1}\\underline{A} + \\underline{S})])\n\n\n\\end{align}\\]\nExpanding the terms inside the square brackets, followed by completing the squares, allows the above expression to be rearranged in the form of a Matrix-variate Normal Inverse Wishart kernel.\n\\[\\begin{align}\n\np(A,\\Sigma|Y,X) &\\sim MNIW(\\bar{A},\\bar{V},\\bar{S},\\bar{\\nu}) \\\\\n\\\\\n\\bar{V} &= (X'(\\lambda I_T)^{-1}X + \\underline{V}^{-1})^{-1} \\\\\n\\bar{A} &= \\bar{V}(X'(\\lambda I_T)^{-1}Y + \\underline{V}^{-1}\\underline{A}) \\\\\n\\bar{S} &= Y'(\\lambda I_T)^{-1}Y + \\underline{A}'\\underline{V}^{-1}\\underline{A} + \\underline{S} - \\bar{A}'\\bar{V}^{-1}\\bar{A} \\\\\n\\bar{\\nu} &= T + \\underline{\\nu}\n\n\\end{align}\\]\nThe posterior distribution for \\(\\lambda\\) is then derived as follows:\n\\[\\begin{align}\n\np(\\lambda|Y,X,A,\\Sigma) &\\propto L(A,\\Sigma,\\lambda|Y,X)p(\\lambda) \\\\\n\\\\\n&= \\det(\\Sigma)^{-\\frac{T}{2}} \\det(\\lambda I_T)^{-\\frac{N}{2}} exp(-\\frac{1}{2} tr[\\Sigma^{-1} (Y-XA)' (\\lambda I_T)^{-1} (Y-XA) ]) \\\\\n&\\times \\lambda^{-\\frac{\\underline{\\nu_{\\lambda}}+2}{2}} exp(-\\frac{1}{2}\\frac{\\underline{s_{\\lambda}}}{\\lambda}) \\\\\n\\\\\n&= \\lambda^{-\\frac{TN}{2}} exp(-\\frac{1}{2}\\frac{1}{\\lambda} tr[\\Sigma^{-1}(Y-XA)'(Y-XA)]) \\\\\n&\\times \\lambda^{-\\frac{\\underline{\\nu_{\\lambda}}+2}{2}} exp(-\\frac{1}{2}\\frac{\\underline{s_{\\lambda}}}{\\lambda}) \\det(\\Sigma)^{-\\frac{T}{2}}\\det(I_T)^{-\\frac{N}{2}} \\\\\n\\\\\n&= \\lambda^{-\\frac{TN+\\underline{\\nu_{\\lambda}}+2}{2}} exp(-\\frac{1}{2}\\frac{1}{\\lambda} [tr[\\Sigma^{-1}(Y-XA)'(Y-XA)] +\\underline{s_{\\lambda}}]) \\det(\\Sigma)^{-\\frac{T}{2}} \\\\\n\\\\\n\\end{align}\\]\nAs such,\n\\[\\begin{align}\n\n\\lambda|Y,A,\\Sigma &\\sim IG2(\\bar{s_{\\lambda}},\\bar{\\nu_{\\lambda}}) \\\\\n\\bar{s_{\\lambda}} &= tr[\\Sigma^{-1}(Y-XA)'(Y-XA)] + \\underline{s_{\\lambda}} \\\\\n\\bar{\\nu_{\\lambda}} &= TN + \\underline{\\nu_{\\lambda}}\n\n\\end{align}\\]\nWe can then sample sequentially from the conditional posterior distributions via a Gibbs Sampler. In order to do so we initalise each of the parameters at arbitrary starting values. We then proceed accordingly:\n\nDraw \\(\\Sigma^{(i)}\\) from the \\(IW(\\bar{S},\\bar{\\nu})\\) distribution\nDraw \\(A^{(i)}\\) from the \\(MN(\\bar{A},\\Sigma^{(i)}, \\bar{V})\\) distribution\nDraw \\(\\lambda^{(i)}\\) from \\(IG2(\\bar{s_{\\lambda}},\\bar{\\nu_{\\lambda}})\\)\n\nWe repeat the above steps for the desired amount of iterations and collect the parameter draws in an array. We can then scrutinise the characteristics of the posterior densities using these draws.\n\nGibbs Sampler code for t-distributed errors:\n\nGS_tdistribution &lt;- function(S, Y_ext, X_ext, priors) {\n  # Set priors\n  A.gprior = priors$A\n  A_V.gprior = priors$V\n  Sigma_s.gprior = priors$s\n  Sigma_v.gprior = priors$nu\n  lambda_s.gprior = priors$lambda_s\n  lambda_v.gprior = priors$lambda_nu\n\n  lambda.draw = lambda_s.gprior/rchisq(1, lambda_v.gprior)\n  \n  # Initialize arrays to store posterior draws\n  Sigma.posterior.draws = array(NA, c(N,N,S))\n  A.posterior.draws = array(NA, c((1+p*N),N,S))\n  lambda.posterior.draws = rep(NA,S)\n\n  # Loop over S iterations\n  for (s in 1:S){\n    lambda.gprior.diag = diag(lambda.draw, nrow(Y_ext))\n    \n    A_V.posterior     = solve(t(X_ext)%*%diag(1/diag(lambda.gprior.diag))%*%X_ext + solve(A_V.gprior))\n    A.posterior       = A_V.posterior%*%(t(X_ext)%*%diag(1/diag(lambda.gprior.diag))%*%Y_ext + solve(A_V.gprior)%*%A.gprior)\n    Sigma_s.posterior = t(Y_ext)%*%diag(1/diag(lambda.gprior.diag))%*%Y_ext + t(A.gprior)%*%solve(A_V.gprior)%*%A.gprior + Sigma_s.gprior - t(A.posterior)%*%solve(A_V.posterior)%*%A.posterior\n    Sigma_v.posterior = nrow(Y_ext) + Sigma_v.gprior\n    \n    Sigma.inv.draw      = rWishart(1, Sigma_v.posterior, solve(Sigma_s.posterior))[,,1]\n    Sigma.posterior.draws[,,s] = solve(Sigma.inv.draw)\n    \n    A.posterior.draws[,,s] = matrix(mvtnorm::rmvnorm(1, mean=as.vector(A.posterior), sigma=Sigma.posterior.draws[,,s]%x%A_V.posterior), ncol=N)\n    \n    lambda_s.posterior = sum(diag(Sigma.inv.draw%*%t(Y_ext - X_ext%*%A.posterior.draws[,,s])%*%(Y_ext - X_ext%*%A.posterior.draws[,,s]))) + lambda_s.gprior\n    lambda_v.posterior = nrow(Y_ext)*2 + lambda_v.gprior\n    \n    lambda.draw = lambda_s.posterior / rchisq(1, lambda_v.posterior)\n    lambda.posterior.draws[s] = lambda.draw\n  }\n  return(list(Sigma.posterior.draws = Sigma.posterior.draws, \n              A.posterior.draws = A.posterior.draws, \n              lambda.posterior.draws = lambda.posterior.draws))\n}\n\ntdist_res_rw = GS_tdistribution(1000, Y_ext, X_ext, c(pris, list(lambda_s=1000, lambda_nu=1000)))\n\n# A posterior mean\nround(apply(tdist_res_rw$A.posterior.draws, 1:2, mean),2)\n\n      [,1]  [,2]\n[1,] -0.38 -0.12\n[2,]  0.98  0.01\n[3,] -0.01  0.99\n\n# Sigma posterior mean\nround(apply(tdist_res_rw$Sigma.posterior.draws, 1:2, mean),2)\n\n      [,1]  [,2]\n[1,]  0.94 -0.01\n[2,] -0.01  0.93\n\n# Lambda posterior mean\nround(mean(tdist_res_rw$lambda.posterior.draws),2)\n\n[1] 1.01\n\n\nAs can be seen, when the extended model estimation routine is applied to the simulated bivariate random walk data, the estimates of \\(A\\) and \\(\\Sigma\\) again match the true parameter values closely."
  },
  {
    "objectID": "index.html#the-extended-model-1",
    "href": "index.html#the-extended-model-1",
    "title": "Exchange Rate Forecasting Using Bayesian VARs Model",
    "section": "The extended model",
    "text": "The extended model\n\nThe prior distribution\n\\[\n\\begin{array}{rcl}\n&A \\mid \\Sigma,{\\color{red}\\kappa} \\sim  \\mathcal{M N} _{T \\times N}(\\underline{A}, \\Sigma, {\\color{red}\\kappa}\\underline{V}) \\\\\n&\\color{red}{\\kappa \\sim \\mathcal{IG2}(\\underline{s}_\\kappa,\\underline{\\nu}_\\kappa)}\\\\\n&\\Sigma \\sim \\mathcal{IW}_{N}(\\underline{S}, \\underline{\\nu})\n\\end{array}\n\\]\n\n\nThe posterior distribution\nIn this section, we will derive the the joint full-conditional posterior distribution of \\(A\\) and \\(\\Sigma\\) and the full-conditional posterior distribution of \\(\\kappa\\).\n\nThe Derivations of the joint full-conditional posterior distribution of A and Sigma\n\\[\n\\begin{aligned}\np(A,\\Sigma \\mid Y,X,{\\color{red}\\kappa}) \\propto L(A, \\Sigma \\mid Y,X) p(A,\\Sigma) = L(A, \\Sigma \\mid Y,X) p(A\\mid\\Sigma,{\\color{red}\\kappa})p(\\Sigma)p({\\color{red}\\kappa})\n\\end{aligned} 4\n\\] Let’s focus on the kernel\n\\[\\begin{aligned}\np(A,\\Sigma \\mid Y,X,{\\color{red}{\\kappa}}) \\propto & det (\\Sigma)^{-\\frac{T}{2}} \\\\\n& \\times \\exp \\left\\{-\\frac{1}{2} \\operatorname{tr}\\left[\\Sigma^{-1}(A-\\widehat{A})^{\\prime} X^{\\prime} X(A-\\widehat{A})\\right]\\right\\} \\\\\n& \\times \\exp \\left\\{-\\frac{1}{2} \\operatorname{tr}\\left[\\Sigma^{-1}(Y-X \\widehat{A})^{\\prime}(Y-X \\widehat{A})\\right]\\right\\} \\\\\n& \\times det(\\Sigma)^{-\\frac{N+K+\\underline{\\nu}+1}{2}} \\\\\n& \\times \\exp \\left\\{-\\frac{1}{2} \\operatorname{tr}\\left[\\Sigma^{-1}(A-\\underline{A})^{\\prime} \\underline{V}^{-1}(A-\\underline{A})\\right]\\right\\} \\\\\n& \\times \\exp \\left\\{-\\frac{1}{2} \\operatorname{tr}\\left[\\Sigma^{-1} \\underline{S}\\right]\\right\\}\\\\\n\n& = \\operatorname{det}(\\Sigma)^{-\\frac{T+N+K+\\underline{\\nu}+1}{2}} \\\\\n& \\times \\exp \\{-\\frac{1}{2} \\operatorname{tr}[\\Sigma^{-1} [(A-\\widehat{A})^{\\prime} X^{\\prime} X(A-\\widehat{A})+(A-\\underline{A})^{\\prime} \\frac{1}{\\kappa} \\underline{V}^{-1}(A-\\underline{A}) \\\\\n& +(Y-X \\widehat{A})^{\\prime}(Y-X \\widehat{A})+\\underline{S}]]\\}\n\n\\end{aligned}\\]\n\\[\\begin{aligned}\n&\n(A-\\widehat{A})^{\\prime} X^{\\prime} X(A-\\widehat{A})\n+(A-\\underline{A})^{\\prime} {\\color{red}{\\frac{1}{\\kappa}}}\\underline{V}^{-1}(A-\\underline{A})\n+(Y-X \\widehat{A})^{\\prime}(Y-X \\widehat{A})\n+\\underline{S} \\\\\n\n& =A^\\prime X^\\prime XA -A^\\prime X^\\prime X \\widehat{A} - \\widehat{A}^\\prime X^\\prime XA + \\widehat{A}^\\prime X^\\prime X \\widehat{A}\n+A^\\prime {\\color{red}{\\frac{1}{\\kappa}}}\\underline{V}^{-1}A - A^\\prime {\\color{red}{\\frac{1}{\\kappa}}}\\underline{V}^{-1} \\underline{A} - \\underline{A}^\\prime {\\color{red}{\\frac{1}{\\kappa}}}\\underline{V}^{-1} A + \\underline{A}^\\prime {\\color{red}{\\frac{1}{\\kappa}}}\\underline{V}^{-1} \\underline{A}\n+ Y^\\prime Y-Y^\\prime X \\widehat{A} - \\widehat{A}^\\prime X^\\prime Y + \\widehat{A}^\\prime X^\\prime X \\widehat{A}+ \\underline{S}\\\\\n\n& =A^\\prime X^\\prime XA -Y^\\prime XA - \\widehat{A}^\\prime X^\\prime XA\n+A^\\prime {\\color{red}{\\frac{1}{\\kappa}}}\\underline{V}^{-1}A - A^\\prime {\\color{red}{\\frac{1}{\\kappa}}}\\underline{V}^{-1} \\underline{A} - \\underline{A}^\\prime {\\color{red}{\\frac{1}{\\kappa}}}\\underline{V}^{-1} A\n+ Y^\\prime Y+ \\underline{S} + \\underline{A}^\\prime {\\color{red}{\\frac{1}{\\kappa}}}\\underline{V}^{-1} \\underline{A}\\\\\n& = A^\\prime (X^\\prime X+ {\\color{red}{\\frac{1}{\\kappa}}}\\underline{V}^{-1})A -2A^\\prime (X^\\prime Y+{\\color{red}{\\frac{1}{\\kappa}}}\\underline{V}^{-1} \\underline{A}) + Y^\\prime Y+ \\underline{S} + \\underline{A}^\\prime {\\color{red}{\\frac{1}{\\kappa}}}\\underline{V}^{-1} \\underline{A}\n\\end{aligned}\\]\n\\[\\begin{aligned}\n\\boxed{\n\\begin{array}{rcl}\n&p(A,\\Sigma \\mid Y,X,{\\color{red}\\kappa})= \\mathcal{MNIW}_{K\\times N}(\\overline{A},\\overline{V},\\overline{S},\\overline{\\nu}) \\\\\n& \\overline{V} = (X^\\prime X + {\\color{red}{\\frac{1}{\\kappa}}}\\underline{V}^{-1})^{-1}\\\\\n& \\overline{A}=\\overline{V}(X^\\prime Y+{\\color{red}{\\frac{1}{\\kappa}}}\\underline{V}^{-1}\\underline{A})\\\\\n& \\overline{\\nu}=T+\\underline{\\nu}\\\\\n& \\overline{S}=\\underline{S}+Y^\\prime Y+\\underline{A}^\\prime \\underline{V}^{-1}{\\color{red}{\\frac{1}{\\kappa}}}\\underline{A}-\\overline{A}^\\prime \\overline{V}^{-1}\\overline{A}\n\\end{array}\n}\n\\end{aligned}\\]\n\n\nThe Derivations of the full-conditional posterior distribution of \\(\\kappa\\)\n\\[\\begin{align}\np(\\kappa \\mid A, \\Sigma, Y,X) & =L(A,\\Sigma \\mid Y,X)p(\\kappa \\mid \\underline{s}_{\\kappa}, \\underline{\\nu}_{\\kappa})p(A,\\Sigma)\\\\\n& =L(A,\\Sigma \\mid Y,X)p(\\kappa \\mid \\underline{s}_{\\kappa}, \\underline{\\nu}_{\\kappa})p(A\\mid \\Sigma)p(\\Sigma)\\\\\n\n&= (\\kappa)^{-\\frac{\\underline{\\nu}+2}{2}}\\exp\\left\\{\\frac{-1}{2}\\frac{\\underline{s}_{\\kappa}}{\\kappa}\\right\\} \\\\\n& \\times det(\\kappa \\underline{V})^{-\\frac{N}{2}}\n\\exp\\left\\{-\\frac{1}{2} \\operatorname{tr}\\left[\\Sigma^{-1}(A-\\underline{A})^{\\prime} \\frac{1}{\\kappa}\\underline{V}^{-1}(A-\\underline{A})\\right]\\right\\} \\\\\n\n&= (\\kappa)^{-\\frac{\\underline{\\nu}+2}{2}}(\\kappa)^{-\\frac{KN}{2}}\\kappa ^{-\\frac{\\underline{\\nu}+KN+2}{2}}\\times \\exp\\left\\{\\frac{-1}{2} \\frac{1}{\\kappa}(\\underline{s}_{\\kappa}+\\operatorname{tr}\\left[\\Sigma^{-1}(A-\\underline{A})^{\\prime} \\underline{V}^{-1}(A-\\underline{A})\\right])\\overline{s}_{\\kappa}\\right\\}\\\\\n\n&= \\kappa ^{-\\frac{\\overbrace{\\underline{\\nu}+KN}^{\\overline{\\nu}_{\\kappa}}+2}{2}}\\times \\exp\\left\\{\\frac{-1}{2} \\frac{1}{\\kappa}\\underbrace{(\\underline{s}_{\\kappa}+\\operatorname{tr}\\left[\\Sigma^{-1}(A-\\underline{A})^{\\prime} \\underline{V}^{-1}(A-\\underline{A})\\right])}_{\\overline{s}_{\\kappa}}\\right\\}\n\n\\end{align}\\]\nWe obtain the following full-conditional posterior distribution of \\(\\kappa\\):\n\\[\n\\boxed{\n\\begin{array}{rcl}\n&\\kappa \\sim \\mathcal{IG2}(\\overline{s}_{\\kappa},\\overline{\\nu}_{\\kappa})\\\\\n& \\overline{s}_{\\kappa}=\\underline{s}_{\\kappa}+\\operatorname{tr}\\left[\\Sigma^{-1}(A-\\underline{A})^{\\prime} \\underline{V}^{-1}(A-\\underline{A})\\right]\\\\\n&\\overline{\\nu}_{\\kappa}=\\underline{\\nu}+KN\n\\end{array}\n}\n\\]"
  },
  {
    "objectID": "index.html#test-for-extended-model",
    "href": "index.html#test-for-extended-model",
    "title": "Exchange Rate Forecasting Using Bayesian VARs Model",
    "section": "Test for extended model",
    "text": "Test for extended model\n\n# setup \nS1                = 5000                             # determine the burn-in draws\nS2                = 45000                            # number of draws from the final simulation\ntotal_S           = S1+S2\nA.posterior       = array(NA, dim = c((1+N*p),N,S1+S2))\nSigma.posterior   = array(NA, dim = c(N,N,S1+S2))\nlambda.posterior  = matrix(NA, S1+S2, 1)\n\n# initial value of lambda\nlambda.posterior[1] = 10                               # set lambda0 \n\n# Prior Gamma distribution: k, theta\nlambda.priors = list(\nalpha = 1\n)\n\n\n\n[1] \"Posterior mean of the autoregressive coefficient matrix A:\"\n\n\n            [,1]        [,2]\n[1,] 0.061630420 0.081440805\n[2,] 0.988556482 0.005130487\n[3,] 0.002628625 0.995523510"
  },
  {
    "objectID": "index.html#proof-of-model-validity",
    "href": "index.html#proof-of-model-validity",
    "title": "Exchange Rate Forecasting Using Bayesian VARs Model",
    "section": "Proof of model validity",
    "text": "Proof of model validity\n\nProof of basic model validity\nTo test the model validity, we simulated 1000 observations from a bi-variate Gaussian random walk process with the covariance matrix equal to the identity matrix of order 2 to see how the autoregressive and the covariance matrices and the posterior mean of the constant term behave.\n\n\n\n\n\n\n## Posterior sample draw\n\n    posterior.draws       = function (S, Y, X){\n  \n    # normal-inverse Wishard posterior parameters\n    V.bar.inv         = t(X)%*%X + diag(1/diag(V.prior))\n    V.bar             = solve(V.bar.inv)\n    A.bar             = V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior)\n    nu.bar            = nrow(Y) + nu.prior\n    S.bar             = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar\n    S.bar.inv         = solve(S.bar)\n  \n    # posterior draws \n    Sigma.posterior   = rWishart(S, df=nu.bar, Sigma=S.bar.inv)\n    Sigma.posterior   = apply(Sigma.posterior,3,solve)\n    Sigma.posterior   = array(Sigma.posterior,c(N,N,S))\n    A.posterior       = array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S))\n    L                 = t(chol(V.bar))\n    for (s in 1:S){\n      A.posterior[,,s]= A.bar + L%*%A.posterior[,,s]%*%chol(Sigma.posterior[,,s])\n    }\n \n    output            = list(A.posterior=A.posterior, Sigma.posterior=Sigma.posterior)\n    return(output)\n}\n\n\n\n[1] \"Posterior mean of the covariance matrix Sigma:\"\n\n\n           [,1]       [,2]\n[1,] 0.98044808 0.08913688\n[2,] 0.08913688 1.01820408\n\n\n\n\n\nPosterior Mean of A\n\n\n\nSimulation_Y1\nSimulation_Y2\n\n\n\n\nConstant\n0.0609321\n0.0765025\n\n\nY1-Lag\n0.9894527\n0.0048336\n\n\nY2-Lag\n0.0023207\n0.9959293\n\n\n\n\n\nThe diagonal entries of the covariance matrix are close to 1, which indicates that each variable has a strong autoregressive relationship with itself and similarly, the diagonal elements of the autoregressive coefficient matrix are close to one, suggesting that each variable is heavily influenced by its past value. Besides, the posterior means for the constant terms is close to 0, the above can indicate that the estimated parameter constant term and means are consistent with what we expect given a Minnesota prior.\n\n\nProof of extended model\nThe Gibbs sampler method will be applied to generate random draws from the full conditional posterior distribution:\n\nDraw \\(\\Sigma^{(s)}\\) from the \\(IW(\\bar{S},\\bar{\\nu})\\) distribution.\nDraw \\(A^{(s)}\\) from the \\(MN(\\bar{A},\\Sigma^{(s)}, \\bar{V})\\) distribution.\nDraw \\(\\lambda_t^{(s)}\\) from \\(GIG(a,b,p)\\).\n\nRepeat steps 1, step 2 and 3 for \\(S_1\\)+\\(S_2\\)times.\nDiscard the first draws that allowed the algorithm to converge to the stationary posterior distribution.\nOutput is \\(\\left\\{ {A^{(s)}, \\Sigma^{(s)}}, \\lambda_t^{(s)}\\right\\}^{S_1+S_2}_{s=S_1+1}\\).\n\n# setup \nS1                = 5000                             # will be discard\nS2                = 45000                            \ntotal_S           = S1+S2\nA.posterior       = array(NA, dim = c((1+N*p),N,S1+S2))\nSigma.posterior   = array(NA, dim = c(N,N,S1+S2))\nlambda.posterior  = matrix(NA, S1+S2, 1)\n\n# set the initial value of lambda\nlambda.posterior[1] = 5                               \n\n# parameter alpha\nlambda.priors = list(alpha = 1)\n\n\n\n[1] \"Posterior mean of the covariance matrix Sigma:\"\n\n\n           [,1]       [,2]\n[1,] 0.97888557 0.08787219\n[2,] 0.08787219 1.01737828\n\n\n\n\n[1] \"Posterior mean of the autoregressive coefficient matrix A:\"\n\n\n            [,1]        [,2]\n[1,] 0.060874386 0.081041438\n[2,] 0.988759465 0.005080126\n[3,] 0.002565558 0.995564443\n\n\nSimilarly, the posterior mean of the autoregressive and the covariance matrices are close to an identity matrix and the posterior mean of the constant term is close to zero, so we can conclude that the extended model is also valid."
  }
]